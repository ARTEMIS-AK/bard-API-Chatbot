{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot w/ Bard API"
      ],
      "metadata": {
        "id": "ib1AG4FukFEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment"
      ],
      "metadata": {
        "id": "OaGoxClLXoP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kK_XBJ1XHGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe03e46-6308-4269-abe3-947a63b7ed1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bardapi in /usr/local/lib/python3.10/dist-packages (0.1.39)\n",
            "Requirement already satisfied: httpx[http2]>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from bardapi) (0.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bardapi) (2.31.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from bardapi) (0.4.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (1.3.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->bardapi) (4.1.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx[http2]>=0.20.0->bardapi) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bardapi) (2.0.7)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->bardapi) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->bardapi) (4.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]>=0.20.0->bardapi) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install bardapi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bardapi import Bard\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "VF1KrU4urUJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace XXXX with the values you get from __Secure-1PSID\n",
        "os.environ['_BARD_API_KEY']=\"g.a000gAgrff7117PPO3pUi2-sw3yuOzdpWmSFOTK0X60llp99EnASfNA91VyRYvIBsxBZLLcB-AACgYKAZ8SAQASFQHGX2Mi24PcNbvaJCYDjGZtbdXJsxoVAUF8yKo9GNJuQn7GYjK1QkjonZS80076\""
      ],
      "metadata": {
        "id": "-rY42uSnXbOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simplest Chatbot"
      ],
      "metadata": {
        "id": "SQW9eevUj8ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your input text\n",
        "# input_text = \"Why is the sky blue?\"\n",
        "input_text = \"capital of india\"\n",
        "print(Bard().get_answer(input_text)['content'])"
      ],
      "metadata": {
        "id": "DFnfJtYbXd_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd02840-89fc-4eb7-91c8-50e7c6fde861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__Secure-1PSID value should end with a single dot. Enter correct __Secure-1PSID value.\n",
            "The capital of India is **New Delhi**. It is part of the National Capital Territory of Delhi (NCT), which also includes the city of Delhi (Old Delhi). New Delhi is home to the seat of all three branches of the Indian government: the Rashtrapati Bhavan (President's House), Sansad Bhavan (Parliament House), and the Supreme Court of India.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Chatbot"
      ],
      "metadata": {
        "id": "8NU1b3f5kdkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Summarizer"
      ],
      "metadata": {
        "id": "x0pzfK-gkzJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6krlXbIVwsZe",
        "outputId": "858b28ae-c7fa-46ab-e8b3-b8db5ec3b533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.12.0-py3-none-any.whl (254 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/254.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/254.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.5/254.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader"
      ],
      "metadata": {
        "id": "P6-zH35Dw0Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ptCfCdRprdOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e687f7-4884-4549-955e-01f79a475f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/1-Build-a-Chatbot/'\n",
        "filename  = 'Attention-Is-All-You-Need.pdf'\n",
        "# filename  = 'Art-of-War.pdf'"
      ],
      "metadata": {
        "id": "n6d42reCXq7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a pdf file object\n",
        "pdfFileObject = open(directory+filename, 'rb')\n",
        "# creating a pdf reader object\n",
        "pdfReader = PdfReader(pdfFileObject)\n",
        "text=[]\n",
        "summary=' '\n",
        "#Storing the pages in a list\n",
        "for i in range(0,len(pdfReader.pages)):\n",
        "  # creating a page object\n",
        "  pageObj = pdfReader.pages[i].extract_text()\n",
        "  pageObj= pageObj.replace('\\t\\r','')\n",
        "  pageObj= pageObj.replace('\\xa0','')\n",
        "  # extracting text from page\n",
        "  text.append(pageObj)"
      ],
      "metadata": {
        "id": "gYpNlLqcZVyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge multiple page - to reduce API Calls\n",
        "def join_elements(lst, chars_per_element):\n",
        "    new_lst = []\n",
        "    for i in range(0, len(lst), chars_per_element):\n",
        "        new_lst.append(''.join(lst[i:i+chars_per_element]))\n",
        "    return new_lst\n",
        "\n",
        "# Option to keep x elements per list element\n",
        "new_text = join_elements(text, 3)\n",
        "\n",
        "print(f\"Original Pages = \",len(text))\n",
        "print(f\"Compressed Pages = \",len(new_text))"
      ],
      "metadata": {
        "id": "0y8iM7trjKdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cab736-bb6a-4125-d4a5-46594bcd97f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Pages =  15\n",
            "Compressed Pages =  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt):\n",
        "  response = Bard().get_answer(prompt)['content']\n",
        "  return response"
      ],
      "metadata": {
        "id": "AJ_lIoBzX267"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(new_text)):\n",
        "  prompt =f\"\"\"\n",
        "  Your task is to act as a Text Summariser.\n",
        "  I'll give you text from  pages of a book from beginning to end.\n",
        "  And your job is to summarise text from these pages in less than 100 words.\n",
        "  Don't be conversational. I need a plain 100 word answer.\n",
        "  Text is shared below, delimited with triple backticks:\n",
        "  ```{text[i]}```\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = get_completion(prompt)\n",
        "  except:\n",
        "    response = get_completion(prompt)\n",
        "  print(response)\n",
        "  summary= summary+' ' +response +'\\n\\n'\n",
        "  # result.append(response)\n",
        "  time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"
      ],
      "metadata": {
        "id": "CxpOAcNuZV3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd843bc-b493-44fe-cc37-962bb17c123e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here is the summary of the text you provided:\n",
            "\n",
            "The paper \"Attention Is All You Need\" proposes a new Transformer architecture for sequence transduction tasks. The Transformer architecture is based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show that the Transformer models are superior in quality, more parallelizable, and require significantly less time to train than previous models. The Transformer architecture also generalizes well to other tasks, such as English constituency parsing.\n",
            "\n",
            "Here are some of the key points of the paper:\n",
            "\n",
            "* The Transformer architecture is based on self-attention, which allows the model to attend to different parts of the input sequence.\n",
            "* The Transformer architecture is more parallelizable than previous models, which makes it faster to train.\n",
            "* The Transformer architecture achieves state-of-the-art results on two machine translation tasks.\n",
            "* The Transformer architecture generalizes well to other tasks, such as English constituency parsing.\n",
            "\n",
            "The paper \"Attention Is All You Need\" is a significant contribution to the field of natural language processing. The Transformer architecture is a powerful new tool for sequence transduction tasks, and it is likely to be used in a wide variety of applications.\n",
            "\n",
            "I hope this summary is helpful. Please let me know if you have any other questions.\n",
            "Response Error: b')]}\\'\\n\\n39\\n[[\"wrb.fr\",null,null,null,null,[13]]]\\n58\\n[[\"di\",5974],[\"af.httprm\",5974,\"-961894757202100084\",0]]\\n25\\n[[\"e\",4,null,null,134]]\\n'. \n",
            "Temporarily unavailable due to traffic or an error in cookie values. Please double-check the cookie values and verify your network environment.\n",
            "Sure, here is the summary of the text you provided:\n",
            "\n",
            "The Transformer model is a neural network architecture for natural language processing (NLP). It is composed of an encoder and decoder stack, each of which is a stack of six identical layers. The encoder stack has two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected feed-forward network. The decoder stack has three sub-layers: the same two sub-layers as the encoder stack, plus a third sub-layer that performs multi-head attention over the output of the encoder stack.\n",
            "\n",
            "The attention function in the Transformer model maps a query and a set of key-value pairs to an output. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\n",
            "\n",
            "The Transformer model has been shown to be very effective for a variety of NLP tasks, including machine translation, text summarization, and question answering.\n",
            "\n",
            "Here is the summary in less than 100 words:\n",
            "\n",
            "The Transformer model is a neural network architecture for NLP that uses attention to learn long-range dependencies. It has been shown to be very effective for a variety of tasks, including machine translation, text summarization, and question answering.\n",
            "\n",
            "Is there anything else I can help you with?\n",
            "Sure, here is the summary of the text you provided:\n",
            "\n",
            "**Scaled Dot-Product Attention**\n",
            "\n",
            "Scaled dot-product attention is a mechanism that computes the relevance of a query to a set of keys. It is a simple but effective attention mechanism that is used in many natural language processing tasks.\n",
            "\n",
            "The scaled dot-product attention algorithm works by first computing the dot product of the query and each key. The dot products are then divided by a scaling factor of **1 / sqrt(dk)**, where **dk** is the dimension of the keys. The softmax function is then applied to the scaled dot products to obtain the weights on the values.\n",
            "\n",
            "**Multi-Head Attention**\n",
            "\n",
            "Multi-head attention is a generalization of scaled dot-product attention that allows for multiple attention heads. Each attention head computes a separate attention weight for each value, which allows the model to attend to different aspects of the input.\n",
            "\n",
            "The multi-head attention algorithm works by first projecting the queries, keys, and values through separate linear layers. The projected queries, keys, and values are then passed through the scaled dot-product attention algorithm, resulting in a set of attention weights for each value. The attention weights are then concatenated and passed through another linear layer to obtain the final output.\n",
            "\n",
            "**Summary**\n",
            "\n",
            "Scaled dot-product attention and multi-head attention are two powerful attention mechanisms that are used in many natural language processing tasks. They are both relatively simple to implement, but they can be very effective at capturing the relationships between different parts of the input.\n",
            "\n",
            "I hope this summary is helpful. Let me know if you have any other questions.\n",
            "Sure, here is the summary of the text you provided:\n",
            "\n",
            "The Transformer model uses multi-head attention to jointly attend to information from different representation subspaces at different positions. This allows the model to learn long-range dependencies and achieve state-of-the-art results on a variety of natural language processing tasks.\n",
            "\n",
            "The Transformer model also uses self-attention layers, which allow each position in the encoder or decoder to attend to all positions in the previous layer. This helps the model to learn the relationships between different parts of the input sequence.\n",
            "\n",
            "In addition to attention and self-attention layers, the Transformer model also uses position-wise feed-forward networks to improve its performance. These networks are applied to each position separately and identically, and they help the model to learn the relative or absolute position of the tokens in the sequence.\n",
            "\n",
            "Overall, the Transformer model is a powerful neural network architecture that has achieved state-of-the-art results on a variety of natural language processing tasks. It is a significant advance over previous models, and it is likely to play an important role in the future of natural language processing.\n",
            "\n",
            "Here are some of the key points from the text:\n",
            "\n",
            "* The Transformer model uses multi-head attention to learn long-range dependencies.\n",
            "* The Transformer model also uses self-attention layers to learn the relationships between different parts of the input sequence.\n",
            "* The Transformer model uses position-wise feed-forward networks to improve its performance.\n",
            "* The Transformer model has achieved state-of-the-art results on a variety of natural language processing tasks.\n",
            "\n",
            "I hope this summary is helpful. Please let me know if you have any other questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(directory +'/bard_summary.txt',\n",
        "          'w') as out:\n",
        "  out.write(summary)"
      ],
      "metadata": {
        "id": "9SilyVEiX29Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mock Interview"
      ],
      "metadata": {
        "id": "X7egGmm2lylv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Chatbot that takes a Mock Interview\n",
        "# For a specific Job Role, provided as input by End-User."
      ],
      "metadata": {
        "id": "kAV64iIplwPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AI Teacher"
      ],
      "metadata": {
        "id": "ww6orEprm-O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This AI Teacher explains you topics in ELI-X level\n",
        "# Where \"X\" is the age-appropriate learner level."
      ],
      "metadata": {
        "id": "ktxJSTM-nABu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Reviewer"
      ],
      "metadata": {
        "id": "9r81CAOhod28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AI helper that generates comprehensive review that cover code\n",
        "# Clarity, structure, efficiency, adherence\n",
        "# To best practices, and maintainability."
      ],
      "metadata": {
        "id": "ItFGGhvQogCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot w/ ChatGPT API"
      ],
      "metadata": {
        "id": "0Sz-Ga9lsdZY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc7SQDTeQLr2"
      },
      "outputs": [],
      "source": [
        "!pip install openai PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import PyPDF2\n",
        "import os\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "H7TURFkhRzzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath= \"/content/drive/MyDrive/1-Build-a-Chatbot/Attention-Is-All-You-Need.pdf\"\n",
        "openai.api_key  = \"Insert-Key-Here\""
      ],
      "metadata": {
        "id": "5j8ORkSRR8Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "  response = openai.ChatCompletion.create(\n",
        "     model=model,\n",
        "     messages=messages,\n",
        "     temperature=0, # this is the degree of randomness of the model's output\n",
        "  )\n",
        "  return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "Se1RoCM8R8OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =f\"\"\"Who is the Prime Minister of India?\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n",
        "time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"
      ],
      "metadata": {
        "id": "8wUSQ_gqTbtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a pdf file object\n",
        "pdfFileObject = open(filepath, 'rb')\n",
        "# creating a pdf reader object\n",
        "pdfReader = PyPDF2.PdfReader(pdfFileObject)\n",
        "text=[]\n",
        "summary=' '\n",
        "#Storing the pages in a list\n",
        "for i in range(0,len(pdfReader.pages)):\n",
        "  # creating a page object\n",
        "  pageObj = pdfReader.pages[i].extract_text()\n",
        "  pageObj= pageObj.replace('\\t\\r','')\n",
        "  pageObj= pageObj.replace('\\xa0','')\n",
        "  # extracting text from page\n",
        "  text.append(pageObj)"
      ],
      "metadata": {
        "id": "PIW2BOdvRz23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "  prompt =f\"\"\"\n",
        "  Your task is to extract relevant information from a text on the page of a book.\n",
        "  This information will be used to create a book summary.\n",
        "  Extract relevant information from the following text, which is delimited with triple backticks.\\\n",
        "  Be sure to preserve the important details.\n",
        "  Text: ```{text[i]}```\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = get_completion(prompt)\n",
        "  except:\n",
        "    response = get_completion(prompt)\n",
        "  print(response)\n",
        "  summary= summary+' ' +response +'\\n\\n'\n",
        "  result.append(response)\n",
        "  time.sleep(19)  #You can query the model only 3 times in a minute for free, so we need to put some delay"
      ],
      "metadata": {
        "id": "iDmLL0C2S35Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/1-Build-a-Chatbot/summary.txt',\n",
        "          'w') as out:\n",
        "  out.write(summary)"
      ],
      "metadata": {
        "id": "x538eUQyTHhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}